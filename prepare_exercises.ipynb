{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7656102c",
   "metadata": {},
   "source": [
    "# Prepare Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca0549",
   "metadata": {},
   "source": [
    "__1) Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:__\n",
    "\n",
    "* Lowercase everything\n",
    "* Normalize unicode characters\n",
    "* Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d51c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import acquire\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05709c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire data for testing\n",
    "blog_articles = acquire.get_blog_articles()\n",
    "\n",
    "news_articles = acquire.get_news_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a28512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    \"\"\"\n",
    "    This function will perform basic cleaning of a string. It will reduce all characters \n",
    "    to lower case, normalize unicode characters, and remove anything that is not a \n",
    "    letter, number, whitespace, or a single quote.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Lower case everything\n",
    "    string = string.lower()\n",
    "    \n",
    "    #Normalize unicode characters, \n",
    "    #encode into ascii byte strings and ignore unknown chars,\n",
    "    #decode back into a UTF-8 string that we can work with\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('UTF-8')\n",
    "    \n",
    "    #Use regex to replace anything that is not a letter, number, whitespace, or a single quote\n",
    "    string = re.sub(r\"[^a-z0-9\\s']\", '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe46965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A WHO technical advisory group which met on Tuesday to consider Bharat Biotech\\'s COVID-19 vaccine Covaxin for emergency use listing is likely to announce its decision soon. \"If all is in place and all goes well and if the committee is satisfied, we would expect a recommendation within the next 24 hours or so,\" WHO spokesperson Margaret Harris told reporters. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = news_articles.content[0]\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f42dd238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a who technical advisory group which met on tuesday to consider bharat biotech's covid19 vaccine covaxin for emergency use listing is likely to announce its decision soon if all is in place and all goes well and if the committee is satisfied we would expect a recommendation within the next 24 hours or so who spokesperson margaret harris told reporters \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For testing\n",
    "cleaned = basic_clean(original)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c519604",
   "metadata": {},
   "source": [
    "__2) Define a function named tokenize. It should take in a string and tokenize all the words in the string.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ec74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    \"\"\"\n",
    "    This function will tokenize all the words in the given string and return the \n",
    "    tokenized string.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    #Use the tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e77703a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a who technical advisory group which met on tuesday to consider bharat biotech's covid19 vaccine covaxin for emergency use listing is likely to announce its decision soon if all is in place and all goes well and if the committee is satisfied we would expect a recommendation within the next 24 hours or so who spokesperson margaret harris told reporters \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For testing\n",
    "#untokenized\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "463ffb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a who technical advisory group which met on tuesday to consider bharat biotech ' s covid19 vaccine covaxin for emergency use listing is likely to announce its decision soon if all is in place and all goes well and if the committee is satisfied we would expect a recommendation within the next 24 hours or so who spokesperson margaret harris told reporters\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenized\n",
    "tokenized = tokenize(cleaned)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d205c72",
   "metadata": {},
   "source": [
    "__3) Define a function named stem. It should accept some text and return the text after applying stemming to all the words.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82462b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    \"\"\"\n",
    "    This function will accept some text and return a stemmed version of the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Create porter stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    #Apply the stemmer to each word in the string to create a list of stemmed words\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    #join our list of stemmed words into a string\n",
    "    string_stemmed = ' '.join(stems)\n",
    "    \n",
    "    return string_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8431be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a who technical advisory group which met on tuesday to consider bharat biotech ' s covid19 vaccine covaxin for emergency use listing is likely to announce its decision soon if all is in place and all goes well and if the committee is satisfied we would expect a recommendation within the next 24 hours or so who spokesperson margaret harris told reporters\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For testing\n",
    "#unstemmed\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e233612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a who technic advisori group which met on tuesday to consid bharat biotech ' s covid19 vaccin covaxin for emerg use list is like to announc it decis soon if all is in place and all goe well and if the committe is satisfi we would expect a recommend within the next 24 hour or so who spokesperson margaret harri told report\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmed\n",
    "stemmed = stem(tokenized)\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef846b44",
   "metadata": {},
   "source": [
    "__4) Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d159473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/johnathonsmith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to download this the first time.\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75a1d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    \"\"\"\n",
    "    This function accepts some text and returns the lemmatized version of the string.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Create the lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    #Use the lemmatizer on each word in the string to create a list of lemmatized words\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    #Join the lemmatized words into one string\n",
    "    string_lemmatized = ' '.join(lemmas)\n",
    "    \n",
    "    return string_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "367d4fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a who technical advisory group which met on tuesday to consider bharat biotech ' s covid19 vaccine covaxin for emergency use listing is likely to announce its decision soon if all is in place and all goes well and if the committee is satisfied we would expect a recommendation within the next 24 hours or so who spokesperson margaret harris told reporters\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For testing\n",
    "#Unlemmatized\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bf5c37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a who technical advisory group which met on tuesday to consider bharat biotech ' s covid19 vaccine covaxin for emergency use listing is likely to announce it decision soon if all is in place and all go well and if the committee is satisfied we would expect a recommendation within the next 24 hour or so who spokesperson margaret harris told reporter\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatized\n",
    "lemmatized = lemmatize(tokenized)\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb89c4",
   "metadata": {},
   "source": [
    "__5) Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.__\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75790729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/johnathonsmith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download the stopword corpus\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b34f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    \"\"\"\n",
    "    This function will accept a string and return a version of the text without any stopwords.\n",
    "    It will also allow the user to add extra words to remove or exclude words from the removal list.\n",
    "    \"\"\"\n",
    "    #Get the standard english stop word list from nltk\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    #Add the extra words to be removed to the stop word list\n",
    "    stop_words.append(extra_words)\n",
    "    \n",
    "    #Remove the words to be excluded from the stop word list\n",
    "    stop_words.remove(exclude_words)\n",
    "    \n",
    "    #Create a list of words to be checked by splitting the given string\n",
    "    words = string.split()\n",
    "    \n",
    "    #Now filter out all of the stop words\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    #Join the list of filtered words into a string\n",
    "    filtered_string = ' '.join(filtered_words)\n",
    "    \n",
    "    return filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "277a6468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a who technical advisory group which met on tuesday to consider bharat biotech ' s covid19 vaccine covaxin for emergency use listing is likely to announce it decision soon if all is in place and all go well and if the committee is satisfied we would expect a recommendation within the next 24 hour or so who spokesperson margaret harris told reporter\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For testing\n",
    "#String with stop words\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2270a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of extra words and words to exclude\n",
    "extra_words = ['group', 'met', 'tuesday']\n",
    "exclude_words = ['a', 'which']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e44bf98b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e63c5b127a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#String without stop words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-93f11e5cfc41>\u001b[0m in \u001b[0;36mremove_stopwords\u001b[0;34m(string, extra_words, exclude_words)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Remove the words to be excluded from the stop word list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mstop_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#Create a list of words to be checked by splitting the given string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "#String without stop words\n",
    "filtered = remove_stopwords(lemmatized, extra_words, exclude_words)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e22cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
